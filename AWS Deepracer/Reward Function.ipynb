{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9326c3",
   "metadata": {},
   "source": [
    "# AWS Deepracer Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93054b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Deepracer Reward Functions are a crucial part to the reinforcement training process. \n",
    "#--The reward function is continously called every 1/15th of a second during the model training process. \n",
    "#--In simple terms, through the input of various variables such as the heading, speed, or steering angle of the car,\n",
    "#--if the model performs a logical, desired action - it is rewarded with the reward variable\n",
    "#--and if it does not adhere to wanted actions, it is penalized. \n",
    "#--The reward function is vital - and there are many different interesting variations of it, some of which can take into account\n",
    "#--more complex variables such as track waypoints, which tie in hand-in-hand to the action space\n",
    "#--(whether it may be continous or discrete)\n",
    "#--Thus, here are 3 reward functions examples in increasing complexity level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea355ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--REWARD FUNCTION 1: DEEPRACER DEFAULT\n",
    "#--This reward function calculates three closest markers to the central line, and rewards the car if it adheres to the boundaries\n",
    "#--It also penalizes the model if it goes away from the central markers\n",
    "def reward_function(params):\n",
    "\n",
    "    # Read input parameters\n",
    "    track_width = params['track_width']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    progress = params['progress']\n",
    "    if params['steps'] == 2:\n",
    "        last.progress = 0.0\n",
    "    x = progress - last.progress\n",
    "    last.progress = progress\n",
    "\n",
    "    # Calculate 3 markers that are increasingly further away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    return x*reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--REWARD FUNCTION 2: STAY INSIDE THE BORDER\n",
    "#--This reward function is not complicated, and simply leaves the agent to decide the best path within the track\n",
    "#--It simply aims to reward the model if it is within the track\n",
    "\n",
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to stay inside the two borders of the track\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    all_wheels_on_track = params['all_wheels_on_track']\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    \n",
    "    # Give a very low reward by default\n",
    "    reward = 1e-3\n",
    "\n",
    "    # Give a high reward if no wheels go off the track and \n",
    "    # the car is somewhere in between the track borders \n",
    "    if all_wheels_on_track and (0.5*track_width - distance_from_center) >= 0.05:\n",
    "        reward = 1.0\n",
    "\n",
    "    # Always return a float value\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--REWARD FUNCTION 3: PREVENT ZIG-ZAG\n",
    "#--This takes into a new variable \"abs_steering\", and penalizes the model if the car is steering too much\n",
    "#--Essentially preventing the zig-zag issue brought up by the default reward function (as it looks at markers along the center line)\n",
    "\n",
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of penalize steering, which helps mitigate zig-zag behaviors\n",
    "    '''\n",
    "    \n",
    "    # Read input parameters\n",
    "    distance_from_center = params['distance_from_center']\n",
    "    track_width = params['track_width']\n",
    "    abs_steering = abs(params['steering_angle']) # Only need the absolute steering angle\n",
    "\n",
    "    # Calculate 3 marks that are farther and father away from the center line\n",
    "    marker_1 = 0.1 * track_width\n",
    "    marker_2 = 0.25 * track_width\n",
    "    marker_3 = 0.5 * track_width\n",
    "\n",
    "    # Give higher reward if the car is closer to center line and vice versa\n",
    "    if distance_from_center <= marker_1:\n",
    "        reward = 1.0\n",
    "    elif distance_from_center <= marker_2:\n",
    "        reward = 0.5\n",
    "    elif distance_from_center <= marker_3:\n",
    "        reward = 0.1\n",
    "    else:\n",
    "        reward = 1e-3  # likely crashed/ close to off track\n",
    "\n",
    "    # Steering penality threshold, change the number based on your action space setting\n",
    "    ABS_STEERING_THRESHOLD = 15 \n",
    "\n",
    "    # Penalize reward if the car is steering too much\n",
    "    if abs_steering > ABS_STEERING_THRESHOLD:\n",
    "        reward *= 0.8\n",
    "\n",
    "    return float(reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23253ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--REWARD FUNCTION 4: WAYPOINTS\n",
    "#--The way waypoints work is that they are simply lane markers along a certain track\n",
    "#--They are usually different for each track, but the advantage is that these points are already pre-established\n",
    "#--This way, the navigation aspect of your model is accelerated, and enhanced - significantly increasing the speed and track completion percentage of the DeepRacer Model\n",
    "\n",
    "\n",
    "import math\n",
    "def reward_function(params):\n",
    "    '''\n",
    "    Example of rewarding the agent to follow center line\n",
    "    '''\n",
    "\n",
    "    # Read input variables\n",
    "    waypoints = params['waypoints']\n",
    "    closest_waypoints = params['closest_waypoints']\n",
    "    heading = params['heading']\n",
    "    x = params['x']\n",
    "    y = params['y']\n",
    "    if closest_waypoints[1] < closest_waypoints[0]:\n",
    "        dir = -1\n",
    "    else:\n",
    "        dir = 1\n",
    "    r_sqr = (params['track_width']*0.9)**2\n",
    "\n",
    "    # Initialize the reward with typical value\n",
    "    reward = 1.0\n",
    "\n",
    "    idx = closest_waypoints[1]\n",
    "    N = len(waypoints)\n",
    "    for i in range(10):\n",
    "        dist = (waypoints[idx][1]-y)**2 + (waypoints[idx][0]-x)**2\n",
    "        if dist >= r_sqr:\n",
    "            break\n",
    "        idx = (idx + dir) % N\n",
    "\n",
    "    # Calculate the direction of the center line based on the closest waypoints\n",
    "    next_point = waypoints[idx]\n",
    "\n",
    "    # Calculate the direction in radius, arctan2(dy, dx), the result is (-pi, pi) in radians\n",
    "    direction = math.atan2(next_point[1] - y, next_point[0] - x)\n",
    "    # Convert to degree\n",
    "    direction = math.degrees(direction)\n",
    "\n",
    "    # Calculate the difference between the track direction and the heading direction of the car\n",
    "    best_steering = direction - heading\n",
    "    steering_angle = params['steering_angle']\n",
    "    error = (steering_angle-best_steering) % 360\n",
    "    if error > 180:\n",
    "        error -= 360\n",
    "    if abs(error >= 60):\n",
    "        reward = 0.01\n",
    "    else:\n",
    "        reward = 1 - abs(error)/60.0\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f025c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Note, to see or visualize all the waypoints on AWS tracks, see: https://github.com/ARCC-RACE/waypoint-visualization\n",
    "\n",
    "#--Or any Github DIR on the internet with 'visualize waypoints AWS DeepRacer'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
